{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Project 1: Standardized Test Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "# Part 1\n",
    "\n",
    "Part 1 requires knowledge of basic Python.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decide on your problem statement that will guide your analysis for this project. For guidelines, sample prompts, or inspiration, check out the README.\n",
    "\n",
    "**To-Do:** *Replace this cell with your problem statement.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents:\n",
    "- [Background](#Background)\n",
    "- [Data Import & Cleaning](#Data-Import-and-Cleaning)\n",
    "- [Exploratory Data Analysis](#Exploratory-Data-Analysis)\n",
    "- [Data Visualization](#Visualize-the-Data)\n",
    "- [Conclusions and Recommendations](#Conclusions-and-Recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SAT and ACT are standardized tests that many colleges and universities in the United States require for their admissions process. This score is used along with other materials such as grade point average (GPA) and essay responses to determine whether or not a potential student will be accepted to the university.\n",
    "\n",
    "The SAT has two sections of the test: Evidence-Based Reading and Writing and Math ([*source*](https://www.princetonreview.com/college/sat-sections)). The ACT has 4 sections: English, Mathematics, Reading, and Science, with an additional optional writing section ([*source*](https://www.act.org/content/act/en/products-and-services/the-act/scores/understanding-your-scores.html)). They have different score ranges, which you can read more about on their websites or additional outside sources (a quick Google search will help you understand the scores for each test):\n",
    "* [SAT](https://collegereadiness.collegeboard.org/sat)\n",
    "* [ACT](https://www.act.org/content/act/en.html)\n",
    "\n",
    "Standardized tests have long been a controversial topic for students, administrators, and legislators. Since the 1940's, an increasing number of colleges have been using scores from sudents' performances on tests like the SAT and the ACT as a measure for college readiness and aptitude ([*source*](https://www.minotdailynews.com/news/local-news/2017/04/a-brief-history-of-the-sat-and-act/)). Supporters of these tests argue that these scores can be used as an objective measure to determine college admittance. Opponents of these tests claim that these tests are not accurate measures of students potential or ability and serve as an inequitable barrier to entry. Lately, more and more schools are opting to drop the SAT/ACT requirement for their Fall 2021 applications ([*read more about this here*](https://www.cnn.com/2020/04/14/us/coronavirus-colleges-sat-act-test-trnd/index.html))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To-Do:** *Fill out this cell (or edit the above cell) with any other background or information that is necessary for your problem statement.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose your Data\n",
    "\n",
    "There are 10 datasets included in the [`data`](./data/) folder for this project. You are required to pick **at least two** of these to complete your analysis. Feel free to use more than two if you would like, or add other relevant datasets you find online.\n",
    "\n",
    "* [`act_2017.csv`](./data/act_2017.csv): 2017 ACT Scores by State\n",
    "* [`act_2018.csv`](./data/act_2018.csv): 2018 ACT Scores by State\n",
    "* [`act_2019.csv`](./data/act_2019.csv): 2019 ACT Scores by State\n",
    "* [`act_2019_ca.csv`](./data/act_2019_ca.csv): 2019 ACT Scores in California by School\n",
    "* [`sat_2017.csv`](./data/sat_2017.csv): 2017 SAT Scores by State\n",
    "* [`sat_2018.csv`](./data/sat_2018.csv): 2018 SAT Scores by State\n",
    "* [`sat_2019.csv`](./data/sat_2019.csv): 2019 SAT Scores by State\n",
    "* [`sat_2019_by_intended_college_major.csv`](./data/sat_2019_by_intended_college_major.csv): 2019 SAT Scores by Intended College Major\n",
    "* [`sat_2019_ca.csv`](./data/sat_2019_ca.csv): 2019 SAT Scores in California by School\n",
    "* [`sat_act_by_college.csv`](./data/sat_act_by_college.csv): Ranges of Accepted ACT & SAT Student Scores by Colleges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To-Do:** *Fill out this cell with the datasets you will use for your analysis. Write a brief description of the contents for each dataset that you choose.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outside Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your problem statement and your chosen datasets, spend some time doing outside research on state policies or additional information that might be relevant. Summarize your findings below. If you bring in any outside tables or charts, make sure you are explicit about having borrowed them. If you quote any text, make sure that it renders as being quoted. **Make sure that you cite your sources.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To-Do:** *Fill out this cell with outside research or any additional background information that will support your analysis.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding Challenges\n",
    "\n",
    "1. Manually calculate mean:\n",
    "\n",
    "    Write a function that takes in values and returns the mean of the values. Create a list of numbers that you test on your function to check to make sure your function works!\n",
    "    \n",
    "    *Note*: Do not use any mean methods built-in to any Python libraries to do this! This should be done without importing any additional libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code:\n",
    "def my_mean(events):\n",
    "    return (sum(events)/len(events))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Function Test\n",
    "numbers = [1,2,3,4,5,6,7,8,9,9,8,7,6,5,4,3,2,1]\n",
    "my_mean(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Manually calculate standard deviation:\n",
    "\n",
    "    The formula for standard deviation is below:\n",
    "\n",
    "    $$\\sigma = \\sqrt{\\frac{1}{n}\\sum_{i=1}^n(x_i - \\mu)^2}$$\n",
    "\n",
    "    Where $x_i$ represents each value in the dataset, $\\mu$ represents the mean of all values in the dataset and $n$ represents the number of values in the dataset.\n",
    "\n",
    "    Write a function that takes in values and returns the standard deviation of the values using the formula above. Hint: use the function you wrote above to calculate the mean! Use the list of numbers you created above to test on your function.\n",
    "    \n",
    "    *Note*: Do not use any standard deviation methods built-in to any Python libraries to do this! This should be done without importing any additional libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code:\n",
    "def std_dev(events):\n",
    "    mean = my_mean(events)\n",
    "    over_n = 1/len(events)\n",
    "    rms = list(map(lambda event: ((event-mean)**2)*over_n, events))\n",
    "    return round(sum(rms)**0.5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.118"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Function Test\n",
    "numbers = (1, 2, 3, 4) \n",
    "std_dev(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Data cleaning function:\n",
    "    \n",
    "    Write a function that takes in a string that is a number and a percent symbol (ex. '50%', '30.5%', etc.) and converts this to a float that is the decimal approximation of the percent. For example, inputting '50%' in your function should return 0.5, '30.5%' should return 0.305, etc. Make sure to test your function to make sure it works!\n",
    "\n",
    "You will use these functions later on in the project!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code:\n",
    "def calc_decimal(percent_string):\n",
    "    return float(percent_string[:-1])/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3567"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Function Test\n",
    "calc_decimal('35.67%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "# Part 2\n",
    "\n",
    "Part 2 requires knowledge of Pandas, EDA, data cleaning, and data visualization.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*All libraries used should be added here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import & Cleaning\n",
    "\n",
    "Import the datasets that you selected for this project and go through the following steps at a minimum. You are welcome to do further cleaning as you feel necessary:\n",
    "1. Display the data: print the first 5 rows of each dataframe to your Jupyter notebook.\n",
    "2. Check for missing values.\n",
    "3. Check for any obvious issues with the observations (keep in mind the minimum & maximum possible values for each test/subtest).\n",
    "4. Fix any errors you identified in steps 2-3.\n",
    "5. Display the data types of each feature.\n",
    "6. Fix any incorrect data types found in step 5.\n",
    "    - Fix any individual values preventing other columns from being the appropriate type.\n",
    "    - If your dataset has a column of percents (ex. '50%', '30.5%', etc.), use the function you wrote in Part 1 (coding challenges, number 3) to convert this to floats! *Hint*: use `.map()` or `.apply()`.\n",
    "7. Rename Columns.\n",
    "    - Column names should be all lowercase.\n",
    "    - Column names should not contain spaces (underscores will suffice--this allows for using the `df.column_name` method to access columns in addition to `df['column_name']`).\n",
    "    - Column names should be unique and informative.\n",
    "8. Drop unnecessary rows (if needed).\n",
    "9. Merge dataframes that can be merged.\n",
    "10. Perform any additional cleaning that you feel is necessary.\n",
    "11. Save your cleaned and merged dataframes as csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\bgrif\\\\Desktop\\\\GA_DSI\\\\projects\\\\project1_SAT_ACT\\\\project_1\\\\code'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Windows\n",
      " Volume Serial Number is 72F8-2D4C\n",
      "\n",
      " Directory of C:\\Users\\bgrif\\Desktop\\GA_DSI\\projects\\project1_SAT_ACT\\project_1\n",
      "\n",
      "09/19/2020  10:25 PM    <DIR>          .\n",
      "09/19/2020  10:25 PM    <DIR>          ..\n",
      "09/19/2020  10:25 PM             1,218 .gitignore\n",
      "09/20/2020  10:21 PM    <DIR>          code\n",
      "09/20/2020  09:59 PM    <DIR>          data\n",
      "09/19/2020  10:25 PM            17,339 README.md\n",
      "               2 File(s)         18,557 bytes\n",
      "               4 Dir(s)  321,994,792,960 bytes free\n"
     ]
    }
   ],
   "source": [
    "#SAT College Board Benchmarks 12th Grade: M-530/ERW-480, 11th Grade: M-510/ERW-970\n",
    "#SAT converted score: ACT-21, SAT-[1060-1090]\n",
    "#https://collegereadiness.collegeboard.org/about/scores/benchmarks\n",
    "%ls .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          NumGE21    PctGE21\n",
      "mean   841.759259  56.757407\n",
      "max   9182.000000  87.100000\n",
      "min      8.000000  20.000000\n",
      "std   1675.299939  17.189004\n",
      "      NumTSTTakr12  PctBothBenchmark12\n",
      "mean   3098.054545           49.723091\n",
      "max   48676.000000           73.180000\n",
      "min      16.000000           18.920000\n",
      "std    7238.653654           13.253115\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 54 entries, 1064 to 1121\n",
      "Data columns (total 18 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   CDS          54 non-null     float64\n",
      " 1   CCode        54 non-null     float64\n",
      " 2   CDCode       54 non-null     float64\n",
      " 3   SCode        54 non-null     float64\n",
      " 4   RType        54 non-null     object \n",
      " 5   SName        0 non-null      object \n",
      " 6   DName        0 non-null      object \n",
      " 7   CName        54 non-null     object \n",
      " 8   Enroll12     54 non-null     float64\n",
      " 9   NumTstTakr   54 non-null     float64\n",
      " 10  AvgScrRead   54 non-null     object \n",
      " 11  AvgScrEng    54 non-null     object \n",
      " 12  AvgScrMath   54 non-null     object \n",
      " 13  AvgScrSci    54 non-null     object \n",
      " 14  NumGE21      54 non-null     float64\n",
      " 15  PctGE21      54 non-null     float64\n",
      " 16  Year         54 non-null     object \n",
      " 17  Unnamed: 17  0 non-null      float64\n",
      "dtypes: float64(9), object(9)\n",
      "memory usage: 8.0+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 55 entries, 1981 to 2578\n",
      "Data columns (total 26 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   CDS                    55 non-null     float64\n",
      " 1   CCode                  55 non-null     float64\n",
      " 2   CDCode                 55 non-null     float64\n",
      " 3   SCode                  55 non-null     float64\n",
      " 4   RType                  55 non-null     object \n",
      " 5   SName                  0 non-null      object \n",
      " 6   DName                  0 non-null      object \n",
      " 7   CName                  55 non-null     object \n",
      " 8   Enroll12               55 non-null     float64\n",
      " 9   NumTSTTakr12           55 non-null     float64\n",
      " 10  NumERWBenchmark12      55 non-null     object \n",
      " 11  PctERWBenchmark12      55 non-null     object \n",
      " 12  NumMathBenchmark12     55 non-null     object \n",
      " 13  PctMathBenchmark12     55 non-null     object \n",
      " 14  Enroll11               55 non-null     float64\n",
      " 15  NumTSTTakr11           55 non-null     float64\n",
      " 16  NumERWBenchmark11      55 non-null     object \n",
      " 17  PctERWBenchmark11      55 non-null     object \n",
      " 18  NumMathBenchmark11     55 non-null     object \n",
      " 19  PctMathBenchmark11     55 non-null     object \n",
      " 20  TotNumBothBenchmark12  55 non-null     object \n",
      " 21  PctBothBenchmark12     55 non-null     float64\n",
      " 22  TotNumBothBenchmark11  55 non-null     object \n",
      " 23  PctBothBenchmark11     55 non-null     object \n",
      " 24  Year                   55 non-null     object \n",
      " 25  Unnamed: 25            0 non-null      float64\n",
      "dtypes: float64(10), object(16)\n",
      "memory usage: 11.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Code:\n",
    "#Import Data Sets\n",
    "actdf = pd.read_csv('../data/act_2019_ca.csv') #2019 ACT Scores in California by School\n",
    "satdf = pd.read_csv('../data/sat_2019_ca.csv') #2019 SAT Scores in California by School\n",
    "collegedf = pd.read_csv('../data/sat_act_by_college.csv') #Ranges of Accepted ACT & SAT Student Scores by Colleges\n",
    "med_incomedf = pd.read_csv('../data/median_household_income_2018.csv') #U.S. Census Bureau\n",
    "equitydf = pd.read_csv('../data/equitable_county_rank.csv') #2019 California School District Equitablility Ranking\n",
    "\n",
    "#Display Data\n",
    "#print(actdf.head())\n",
    "#print(satdf.head())\n",
    "#print(collegedf.head())\n",
    "#print(equitydf.head())\n",
    "\n",
    "#Drop the empty (last) row\n",
    "actdf.drop(actdf.tail(1).index,inplace=True)\n",
    "satdf.drop(satdf.tail(1).index,inplace=True)\n",
    "\n",
    "#RType == 'C' entries contain aggregate County info\n",
    "act_countydf = actdf[actdf['RType'] == 'C']\n",
    "sat_countydf = satdf[satdf['RType'] == 'C']\n",
    "\n",
    "#RType == 'D' entries contain aggregate School District info\n",
    "act_districtdf = actdf[actdf['RType'] == 'D']\n",
    "sat_districtdf = satdf[satdf['RType'] == 'D']\n",
    "\n",
    "#Create filters for special cases where score records are not available(or don't exist)\n",
    "#Filter out DISTRICT records where no seniors took exam, but more than 15 were enrolled\n",
    "null_district_actdf = act_districtdf[act_districtdf['PctGE21'].isnull()==False]\n",
    "null_district_satdf = sat_districtdf[sat_districtdf['PctBothBenchmark12'].isnull()==False]\n",
    "#Filter out COUNTY records where no seniors took exam, but more than 15 were enrolled\n",
    "null_county_actdf = act_countydf[act_countydf['PctGE21'].isnull()==False]\n",
    "null_county_satdf = sat_countydf[sat_countydf['PctBothBenchmark12'].isnull()==False]\n",
    "\n",
    "#Filter out DISTRICT records where less than 15 enrolled seniors took exam\n",
    "district_scores_actdf = null_district_actdf[null_district_actdf['PctGE21']!='*'].copy()\n",
    "district_scores_satdf = null_district_satdf[null_district_satdf['PctBothBenchmark12']!='*'].copy()\n",
    "#Filter out COUNTY records where less than 15 enrolled seniors took exam\n",
    "county_scores_actdf = null_county_actdf[null_county_actdf['PctGE21']!='*'].copy()\n",
    "county_scores_satdf = null_county_satdf[null_county_satdf['PctBothBenchmark12']!='*'].copy()\n",
    "\n",
    "\n",
    "\n",
    "#print(act_countydf.groupby('RType')[['NumTstTakr','Enroll12']].agg( ['mean', 'max', 'min', 'std'] ))\n",
    "#print(act_countydf[['CName','NumGE21','PctGE21']].info());\n",
    "#print(act_countydf['NumTstTakr'].std())\n",
    "\n",
    "#Use this code later to look at statistics after adding a column pct_participation = ('NumTstTakr' / 'Enroll12')\n",
    "#print(act_countydf[['NumTstTakr', 'Enroll12']].agg( ['mean', 'max', 'min', 'std'] ))\n",
    "#print(act_districtdf.groupby('CName')[['NumTstTakr','Enroll12']].agg( ['mean', 'max', 'min', 'std'] ))\n",
    "\n",
    "'''for row in actdf.index:\n",
    "    if actdf['PctGE21'][row].isnull()==False:\n",
    "        print(actdf[actdf['PctGE21'].isnull()==False])\n",
    "        print(actdf[actdf['PctGE21']=='*'])'''\n",
    "\n",
    "#act_scoresdf.dropna(inplace=True)\n",
    "#act_scores = act_scoresdf[act_scoresdf['PctGE21'] != 'NaN']\n",
    "#print(act_scoresdf.info())\n",
    "#sat_scoresdf = \n",
    "\n",
    "#Drop comma from median household income column\n",
    "for row in range(58):\n",
    "    med_incomedf['median_household_income'] = med_incomedf['median_household_income'][row].replace(',','')\n",
    "#print(actdf.columns)\n",
    "\n",
    "#Fix Incorrect Data Types\n",
    "actdf['CCode'] = actdf['CCode'].apply(int)\n",
    "satdf['CCode'] = satdf['CCode'].apply(int)\n",
    "\n",
    "actdf['CDCode'] = actdf['CDCode'].apply(int)\n",
    "satdf['CDCode'] = satdf['CDCode'].apply(int)\n",
    "\n",
    "actdf['Enroll12'] = actdf['Enroll12'].apply(int)\n",
    "satdf['Enroll12'] = satdf['Enroll12'].apply(int)\n",
    "\n",
    "actdf['NumTstTakr'] = actdf['NumTstTakr'].apply(int)\n",
    "satdf['NumTSTTakr12'] = satdf['NumTSTTakr12'].apply(int)\n",
    "\n",
    "#Additional column dtypes to fix for 'PctGE21'-(ACT data) & 'PctBothBenchmark12'-(SAT data)\n",
    "county_scores_actdf['NumGE21'] = county_scores_actdf['NumGE21'].apply(float)\n",
    "county_scores_actdf['PctGE21'] = county_scores_actdf['PctGE21'].apply(float)\n",
    "\n",
    "county_scores_satdf['NumTSTTakr12'] = county_scores_satdf['NumTSTTakr12'].apply(float)\n",
    "county_scores_satdf['PctBothBenchmark12'] = county_scores_satdf['PctBothBenchmark12'].apply(float)\n",
    "\n",
    "print(county_scores_actdf[['NumGE21','PctGE21']].agg( ['mean', 'max', 'min', 'std'] ))\n",
    "print(county_scores_satdf[['NumTSTTakr12','PctBothBenchmark12']].agg( ['mean', 'max', 'min', 'std'] ))\n",
    "\n",
    "district_scores_actdf['PctGE21'] = district_scores_actdf['PctGE21'].apply(float)\n",
    "#print(district_scores_actdf.groupby('DName')['PctGE21'].agg(['mean', 'max', 'min', 'std']))\n",
    "med_incomedf['median_household_income'] = med_incomedf['median_household_income'].apply(int)\n",
    "\n",
    "#Check df for changes\n",
    "#print(act_countydf.info())\n",
    "#print(sat_countydf.info())\n",
    "print(county_scores_actdf.info())\n",
    "print(county_scores_satdf.info())\n",
    "\n",
    "#Remove excess columns\n",
    "actdf = actdf[['CCode', 'CDCode', 'RType', 'DName', 'CName', 'Enroll12', 'NumTstTakr','NumGE21', 'PctGE21']]\n",
    "satdf = satdf[['CCode', 'CDCode', 'RType', 'CName','Enroll12', 'NumTSTTakr12', 'TotNumBothBenchmark12', 'PctBothBenchmark12']]\n",
    "\n",
    "#Rename Columns\n",
    "actdf = actdf.rename(columns={'CCode':'county_code', 'CDCode':'district_code', 'RType':'record_type', 'DName':'district', 'CName':'county','Enroll12':'enrolled', 'NumTstTakr':'tested', 'NumGE21':'surpassed', 'PctGE21':'pct_surpassed'})\n",
    "satdf = satdf.rename(columns={'CCode':'county_code', 'CDCode':'district_code', 'RType':'record_type', 'CName':'county','Enroll12':'enrolled', 'NumTSTTakr12':'tested', 'TotNumBothBenchmark12':'surpassed', 'PctBothBenchmark12':'pct_surpassed'})\n",
    "equitydf = equitydf.rename(columns={'Rank*':'rank', 'School District':'district', 'Score':'score','Expenditures for Public Elementary and Secondary Schools per Pupil':'expenditures_per_pupil','Income by School District':'income'})\n",
    "\n",
    "#Additional Cleaning\n",
    "#ID equitable counties from respective districts\n",
    "\n",
    "\n",
    "\n",
    "#print(satdf.info())\n",
    "#print(med_incomedf.info())\n",
    "#print(equitydf.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "distcount_dict = {}\n",
    "for row in actdf.index:\n",
    "    #print(row)\n",
    "    c = actdf['county'][row]\n",
    "    d = actdf['district'][row]\n",
    "    #print(c)\n",
    "    #print(d)\n",
    "    if c in distcount_dict:\n",
    "        if d not in distcount_dict[c]:\n",
    "            distcount_dict[c].append(d)\n",
    "    else:\n",
    "        #distcount_dict[c] = set([d])\n",
    "        #distcount_dict.update({c:d}) \n",
    "        distcount_dict.update({c:[d]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Riverside', 'Los Angeles', 'Kern', 'Santa Clara', 'San Francisco', 'San Bernardino', 'Humboldt', 'Contra Costa', 'Tulare', 'Ventura', 'Alameda', 'Monterey', 'Orange', 'Santa Barbara', 'Amador', 'Fresno', 'Napa', 'Sonoma', 'Shasta', 'Mendocino', 'Solano', 'Placer', 'San Benito', 'Santa Cruz', 'San Mateo', 'San Luis Obispo', 'Sacramento', 'San Joaquin', 'Stanislaus', 'Merced', 'San Diego', 'Kings', 'Nevada', 'Lassen', 'Butte', 'Inyo', 'Imperial', 'Calaveras', 'Siskiyou', 'Lake', 'Trinity', 'Sutter', 'Del Norte', 'El Dorado', 'Madera', 'Plumas', 'Mono', 'Colusa', 'Tuolumne', 'Yuba', 'Tehama', 'Yolo', 'Glenn', 'Sierra', 'Mariposa', 'Modoc', 'Marin', 'Alpine', 'State of California'])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distcount_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Beaumont Unified',\n",
       " 'Riverside Unified',\n",
       " 'Banning Unified',\n",
       " 'Perris Union High',\n",
       " 'California School for the Deaf-Riverside (State Special Schl)',\n",
       " 'Moreno Valley Unified',\n",
       " 'Palm Springs Unified',\n",
       " 'Corona-Norco Unified',\n",
       " 'Temecula Valley Unified',\n",
       " 'Val Verde Unified',\n",
       " 'Coachella Valley Unified',\n",
       " 'Lake Elsinore Unified',\n",
       " 'Riverside County Office of Education',\n",
       " 'Hemet Unified',\n",
       " 'Alvord Unified',\n",
       " 'Desert Sands Unified',\n",
       " 'Jurupa Unified',\n",
       " 'San Jacinto Unified',\n",
       " 'Murrieta Valley Unified',\n",
       " nan,\n",
       " 'Menifee Union Elementary',\n",
       " 'Nuview Union ',\n",
       " 'Palo Verde Unified',\n",
       " 'Nuview Union']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distcount_dict.get('Riverside')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-5db23f1c4f1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'county'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "actdf['county'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1391       Alvord Unified\n",
      "1673       Alvord Unified\n",
      "711        Alvord Unified\n",
      "839        Alvord Unified\n",
      "139       Banning Unified\n",
      "              ...        \n",
      "2182    Val Verde Unified\n",
      "311     Val Verde Unified\n",
      "1410    Val Verde Unified\n",
      "1749    Val Verde Unified\n",
      "1093                  NaN\n",
      "Name: district, Length: 108, dtype: object\n"
     ]
    }
   ],
   "source": [
    "actdf[actdf['county']=='Riverside']['district'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county_code</th>\n",
       "      <th>district_code</th>\n",
       "      <th>record_type</th>\n",
       "      <th>district</th>\n",
       "      <th>county</th>\n",
       "      <th>enrolled</th>\n",
       "      <th>tested</th>\n",
       "      <th>surpassed</th>\n",
       "      <th>pct_surpassed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>3366993</td>\n",
       "      <td>S</td>\n",
       "      <td>Beaumont Unified</td>\n",
       "      <td>Riverside</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>33</td>\n",
       "      <td>3367215</td>\n",
       "      <td>S</td>\n",
       "      <td>Riverside Unified</td>\n",
       "      <td>Riverside</td>\n",
       "      <td>434</td>\n",
       "      <td>123</td>\n",
       "      <td>40</td>\n",
       "      <td>32.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>33</td>\n",
       "      <td>3366985</td>\n",
       "      <td>S</td>\n",
       "      <td>Banning Unified</td>\n",
       "      <td>Riverside</td>\n",
       "      <td>218</td>\n",
       "      <td>51</td>\n",
       "      <td>13</td>\n",
       "      <td>25.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>33</td>\n",
       "      <td>3366985</td>\n",
       "      <td>S</td>\n",
       "      <td>Banning Unified</td>\n",
       "      <td>Riverside</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>33</td>\n",
       "      <td>3366993</td>\n",
       "      <td>S</td>\n",
       "      <td>Beaumont Unified</td>\n",
       "      <td>Riverside</td>\n",
       "      <td>652</td>\n",
       "      <td>48</td>\n",
       "      <td>23</td>\n",
       "      <td>47.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>33</td>\n",
       "      <td>3367124</td>\n",
       "      <td>S</td>\n",
       "      <td>Moreno Valley Unified</td>\n",
       "      <td>Riverside</td>\n",
       "      <td>450</td>\n",
       "      <td>121</td>\n",
       "      <td>23</td>\n",
       "      <td>19.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2225</th>\n",
       "      <td>33</td>\n",
       "      <td>3375200</td>\n",
       "      <td>S</td>\n",
       "      <td>Murrieta Valley Unified</td>\n",
       "      <td>Riverside</td>\n",
       "      <td>884</td>\n",
       "      <td>165</td>\n",
       "      <td>111</td>\n",
       "      <td>67.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2256</th>\n",
       "      <td>33</td>\n",
       "      <td>3373676</td>\n",
       "      <td>S</td>\n",
       "      <td>Coachella Valley Unified</td>\n",
       "      <td>Riverside</td>\n",
       "      <td>63</td>\n",
       "      <td>4</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2258</th>\n",
       "      <td>33</td>\n",
       "      <td>3367082</td>\n",
       "      <td>S</td>\n",
       "      <td>Hemet Unified</td>\n",
       "      <td>Riverside</td>\n",
       "      <td>437</td>\n",
       "      <td>72</td>\n",
       "      <td>25</td>\n",
       "      <td>34.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2259</th>\n",
       "      <td>33</td>\n",
       "      <td>3367082</td>\n",
       "      <td>S</td>\n",
       "      <td>Hemet Unified</td>\n",
       "      <td>Riverside</td>\n",
       "      <td>67</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>76.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      county_code  district_code record_type                  district  \\\n",
       "0              33        3366993           S          Beaumont Unified   \n",
       "100            33        3367215           S         Riverside Unified   \n",
       "139            33        3366985           S           Banning Unified   \n",
       "140            33        3366985           S           Banning Unified   \n",
       "148            33        3366993           S          Beaumont Unified   \n",
       "...           ...            ...         ...                       ...   \n",
       "2222           33        3367124           S     Moreno Valley Unified   \n",
       "2225           33        3375200           S   Murrieta Valley Unified   \n",
       "2256           33        3373676           S  Coachella Valley Unified   \n",
       "2258           33        3367082           S             Hemet Unified   \n",
       "2259           33        3367082           S             Hemet Unified   \n",
       "\n",
       "         county  enrolled  tested surpassed pct_surpassed  \n",
       "0     Riverside        18       0       NaN           NaN  \n",
       "100   Riverside       434     123        40         32.52  \n",
       "139   Riverside       218      51        13         25.49  \n",
       "140   Riverside        91       0       NaN           NaN  \n",
       "148   Riverside       652      48        23         47.92  \n",
       "...         ...       ...     ...       ...           ...  \n",
       "2222  Riverside       450     121        23         19.01  \n",
       "2225  Riverside       884     165       111         67.27  \n",
       "2256  Riverside        63       4         *             *  \n",
       "2258  Riverside       437      72        25         34.72  \n",
       "2259  Riverside        67      21        16         76.19  \n",
       "\n",
       "[108 rows x 9 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actdf[actdf['county']=='Riverside']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hemet Unified'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distcount_dict['Riverside']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'county'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2645\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2646\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'county'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-173-175f259addea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'district'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mequitydf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'district'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mactdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'district'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m             \u001b[0mequitydf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'county'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mactdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'county'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mequitydf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'district'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m' found'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2798\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2799\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2800\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2646\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2648\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2650\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'county'"
     ]
    }
   ],
   "source": [
    "for row in range(len(equitydf['district'])):\n",
    "    for index in range(len(actdf['district'])):\n",
    "        if equitydf['district'][row] == actdf['district'][index]:\n",
    "            equitydf['county'][row] = actdf['county'][index]\n",
    "            print(equitydf['district'][row]+' found')\n",
    "            \n",
    "equitydf['county']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(equitydf['county'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>county</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alameda</th>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amador</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Butte</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calaveras</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Colusa</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contra Costa</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Del Norte</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>El Dorado</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fresno</th>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glenn</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humboldt</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Imperial</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inyo</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kern</th>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kings</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lake</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lassen</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Los Angeles</th>\n",
       "      <td>465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Madera</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marin</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mariposa</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mendocino</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Merced</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Modoc</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mono</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monterey</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Napa</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nevada</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orange</th>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Placer</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Plumas</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Riverside</th>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sacramento</th>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>San Benito</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>San Bernardino</th>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>San Diego</th>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>San Francisco</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>San Joaquin</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>San Luis Obispo</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>San Mateo</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Santa Barbara</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Santa Clara</th>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Santa Cruz</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shasta</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sierra</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Siskiyou</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Solano</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sonoma</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stanislaus</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State of California</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sutter</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tehama</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trinity</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tulare</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tuolumne</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ventura</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yolo</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yuba</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     district\n",
       "county                       \n",
       "Alameda                    87\n",
       "Amador                      5\n",
       "Butte                      25\n",
       "Calaveras                   7\n",
       "Colusa                      9\n",
       "Contra Costa               55\n",
       "Del Norte                   4\n",
       "El Dorado                  14\n",
       "Fresno                     84\n",
       "Glenn                      10\n",
       "Humboldt                   21\n",
       "Imperial                   17\n",
       "Inyo                        8\n",
       "Kern                       54\n",
       "Kings                      17\n",
       "Lake                       12\n",
       "Lassen                      9\n",
       "Los Angeles               465\n",
       "Madera                     17\n",
       "Marin                      15\n",
       "Mariposa                    2\n",
       "Mendocino                  21\n",
       "Merced                     25\n",
       "Modoc                       4\n",
       "Mono                        6\n",
       "Monterey                   33\n",
       "Napa                       11\n",
       "Nevada                     11\n",
       "Orange                    108\n",
       "Placer                     30\n",
       "Plumas                      5\n",
       "Riverside                 107\n",
       "Sacramento                 78\n",
       "San Benito                  4\n",
       "San Bernardino            120\n",
       "San Diego                 178\n",
       "San Francisco              23\n",
       "San Joaquin                55\n",
       "San Luis Obispo            23\n",
       "San Mateo                  34\n",
       "Santa Barbara              34\n",
       "Santa Clara                72\n",
       "Santa Cruz                 24\n",
       "Shasta                     25\n",
       "Sierra                      2\n",
       "Siskiyou                   15\n",
       "Solano                     22\n",
       "Sonoma                     45\n",
       "Stanislaus                 43\n",
       "State of California         1\n",
       "Sutter                     20\n",
       "Tehama                      8\n",
       "Trinity                     5\n",
       "Tulare                     45\n",
       "Tuolumne                   10\n",
       "Ventura                    43\n",
       "Yolo                       14\n",
       "Yuba                       10"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for index in range(len(equitydf['district'])):\n",
    "    #equitydf.loc[ index, [ 'district' ] ]  = equitydf['district'][index].replace('School District','')\n",
    "#equitydf.loc[ :, [ 'district' ] ]  \n",
    "#for index in range(len(equitydf['district'])):\n",
    "    #actdf['district'].str.find(equitydf['district'][index], start=0, end=None).unique()\n",
    "df = actdf.loc[ :, [ 'county', 'district' ] ].sort_values('district').dropna()\n",
    "#df.set_index('county')['district'].to_dict()\n",
    "#actdf['district'].unique()\n",
    "#actdf.sort_values('district').head(25)\n",
    "#data_dict = actdf.to_dict()\n",
    "#districts = list(actdf['district'].unique())\n",
    "grouped = df.groupby(df['county'])\n",
    "grouped.count()\n",
    "#Parameters:\n",
    "#sub: String or character to be searched in the text value in series\n",
    "#start: int value, start point of searching. Default is 0 which means from the beginning of string\n",
    "#end: int value, end point where the search needs to be stopped. Default is None."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### actdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Rank*', 'School District', 'Score',\n",
      "       'Expenditures for Public Elementary and Secondary Schools per Pupil',\n",
      "       'Income by School District'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(equitydf.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dictionary\n",
    "\n",
    "Now that we've fixed our data, and given it appropriate names, let's create a [data dictionary](http://library.ucmerced.edu/node/10249). \n",
    "\n",
    "A data dictionary provides a quick overview of features/variables/columns, alongside data types and descriptions. The more descriptive you can be, the more useful this document is.\n",
    "\n",
    "Example of a Fictional Data Dictionary Entry: \n",
    "\n",
    "|Feature|Type|Dataset|Description|\n",
    "|---|---|---|---|\n",
    "|**county_pop**|*integer*|2010 census|The population of the county (units in thousands, where 2.5 represents 2500 people).| \n",
    "|**per_poverty**|*float*|2010 census|The percent of the county over the age of 18 living below the 200% of official US poverty rate (units percent to two decimal places 98.10 means 98.1%)|\n",
    "\n",
    "[Here's a quick link to a short guide for formatting markdown in Jupyter notebooks](https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html).\n",
    "\n",
    "Provided is the skeleton for formatting a markdown table, with columns headers that will help you create a data dictionary to quickly summarize your data, as well as some examples. **This would be a great thing to copy and paste into your custom README for this project.**\n",
    "\n",
    "*Note*: if you are unsure of what a feature is, check the source of the data! This can be found in the README."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To-Do:** *Edit the table below to create your own data dictionary for the datasets you chose.*\n",
    "\n",
    "|Feature|Type|Dataset|Description|\n",
    "|---|---|---|---|\n",
    "|column name|int/float/object|ACT/SAT|This is an example| \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "Complete the following steps to explore your data. You are welcome to do more EDA than the steps outlined here as you feel necessary:\n",
    "1. Summary Statistics.\n",
    "2. Use a **dictionary comprehension** to apply the standard deviation function you create in part 1 to each numeric column in the dataframe.  **No loops**.\n",
    "    - Assign the output to variable `sd` as a dictionary where: \n",
    "        - Each column name is now a key \n",
    "        - That standard deviation of the column is the value \n",
    "        - *Example Output :* `{'ACT_Math': 120, 'ACT_Reading': 120, ...}`\n",
    "3. Investigate trends in the data.\n",
    "    - Using sorting and/or masking (along with the `.head()` method to avoid printing our entire dataframe), consider questions relevant to your problem statement. Some examples are provided below (but feel free to change these questions for your specific problem):\n",
    "        - Which states have the highest and lowest participation rates for the 2017, 2019, or 2019 SAT and ACT?\n",
    "        - Which states have the highest and lowest mean total/composite scores for the 2017, 2019, or 2019 SAT and ACT?\n",
    "        - Do any states with 100% participation on a given test have a rate change year-to-year?\n",
    "        - Do any states show have >50% participation on *both* tests each year?\n",
    "        - Which colleges have the highest median SAT and ACT scores for admittance?\n",
    "        - Which California school districts have the highest and lowest mean test scores?\n",
    "    - **You should comment on your findings at each step in a markdown cell below your code block**. Make sure you include at least one example of sorting your dataframe by a column, and one example of using boolean filtering (i.e., masking) to select a subset of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To-Do:** *Edit this cell with your findings on trends in the data (step 3 above).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Data\n",
    "\n",
    "There's not a magic bullet recommendation for the right number of plots to understand a given dataset, but visualizing your data is *always* a good idea. Not only does it allow you to quickly convey your findings (even if you have a non-technical audience), it will often reveal trends in your data that escaped you when you were looking only at numbers. It is important to not only create visualizations, but to **interpret your visualizations** as well.\n",
    "\n",
    "**Every plot should**:\n",
    "- Have a title\n",
    "- Have axis labels\n",
    "- Have appropriate tick labels\n",
    "- Text is legible in a plot\n",
    "- Plots demonstrate meaningful and valid relationships\n",
    "- Have an interpretation to aid understanding\n",
    "\n",
    "Here is an example of what your plots should look like following the above guidelines. Note that while the content of this example is unrelated, the principles of visualization hold:\n",
    "\n",
    "![](https://snag.gy/hCBR1U.jpg)\n",
    "*Interpretation: The above image shows that as we increase our spending on advertising, our sales numbers also tend to increase. There is a positive correlation between advertising spending and sales.*\n",
    "\n",
    "---\n",
    "\n",
    "Here are some prompts to get you started with visualizations. Feel free to add additional visualizations as you see fit:\n",
    "1. Use Seaborn's heatmap with pandas `.corr()` to visualize correlations between all numeric features.\n",
    "    - Heatmaps are generally not appropriate for presentations, and should often be excluded from reports as they can be visually overwhelming. **However**, they can be extremely useful in identify relationships of potential interest (as well as identifying potential collinearity before modeling).\n",
    "    - Please take time to format your output, adding a title. Look through some of the additional arguments and options. (Axis labels aren't really necessary, as long as the title is informative).\n",
    "2. Visualize distributions using histograms. If you have a lot, consider writing a custom function and use subplots.\n",
    "    - *OPTIONAL*: Summarize the underlying distributions of your features (in words & statistics)\n",
    "         - Be thorough in your verbal description of these distributions.\n",
    "         - Be sure to back up these summaries with statistics.\n",
    "         - We generally assume that data we sample from a population will be normally distributed. Do we observe this trend? Explain your answers for each distribution and how you think this will affect estimates made from these data.\n",
    "3. Plot and interpret boxplots. \n",
    "    - Boxplots demonstrate central tendency and spread in variables. In a certain sense, these are somewhat redundant with histograms, but you may be better able to identify clear outliers or differences in IQR, etc.\n",
    "    - Multiple values can be plotted to a single boxplot as long as they are of the same relative scale (meaning they have similar min/max values).\n",
    "    - Each boxplot should:\n",
    "        - Only include variables of a similar scale\n",
    "        - Have clear labels for each variable\n",
    "        - Have appropriate titles and labels\n",
    "4. Plot and interpret scatter plots to view relationships between features. Feel free to write a custom function, and subplot if you'd like. Functions save both time and space.\n",
    "    - Your plots should have:\n",
    "        - Two clearly labeled axes\n",
    "        - A proper title\n",
    "        - Colors and symbols that are clear and unmistakable\n",
    "5. Additional plots of your choosing.\n",
    "    - Are there any additional trends or relationships you haven't explored? Was there something interesting you saw that you'd like to dive further into? It's likely that there are a few more plots you might want to generate to support your narrative and recommendations that you are building toward. **As always, make sure you're interpreting your plots as you go**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your exploration of the data, what are you key takeaways and recommendations? Make sure to answer your question of interest or address your problem statement here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To-Do:** *Edit this cell with your conclusions and recommendations.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget to create your README!\n",
    "\n",
    "**To-Do:** *If you combine your problem statement, data dictionary, brief summary of your analysis, and conclusions/recommendations, you have an amazing README.md file that quickly aligns your audience to the contents of your project.* Don't forget to cite your data sources!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
